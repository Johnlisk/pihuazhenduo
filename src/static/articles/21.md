# 浅谈python的进程池——`multiprocessing.Pool`与`concurrent.futures.ProcessPoolExecutor`
------------
最近接到一个需求，从一个es的index取数据进行计算，再把计算结果存储到另一个index。因为数据量比较大，需要进行并行操作。

使用`multiprocessing.Pool`进程池，在需要一个各进程全局的变量时，使用Manager相关的方法实例化需要的变量:  
*引用官方文档https://docs.python.org/zh-cn/3/library/multiprocessing.html#sharing-state-between-processes :  
在使用进程池时，若想进行进程间通信可以使用管理器对象`Manager`，由 `Manager()` 返回的管理器对象控制一个服务进程，
该进程保存Python对象并允许其他进程使用代理操作它们。  
Manager() 返回的管理器支持类型： `list` 、 `dict` 、 `Namespace` 、 `Lock` 、
 `RLock` 、 `Semaphore` 、 `BoundedSemaphore` 、 `Condition` 、 `Event` 、 `Barrier` 、
  `Queue` 、 `Value` 和 `Array` 。  
使用服务进程的管理器比使用共享内存对象更灵活，因为它们可以支持任意对象类型。
此外，单个管理器可以通过网络由不同计算机上的进程共享。但是，它们比使用共享内存慢。  
以下代码使用`multiprocessing.Pool`创建了一个包含四个进程的进程池，并使用一个`Manager().dict()`
作为锁，`Manager().Queue()`进行父子进程间的通信/数据共享

```python
from multiprocessing import Manager, Pool
pool = Pool(4)
# 多个进程之间公用的变量
onlock_dict = Manager().dict() # 作为锁使用的字典
queue = Manager().Queue() # 通信用队列

def handle(q):
    data = q.get()
    dosomething(data) # 业务逻辑之类的
    did = onlock_dict.pop(data.id)# 释放锁

datas = get_data() #获取数据

for d in datas:
    if d.id in onlock_dict.keys():
        datas.append(d)
    else:
        onlock_dict[d.id] = 1
        queue.put(d)
        pool.apply(handle, (queue,)) # 同步执行
        # pool.apply_async(handle, (queue,)) # 异步非阻塞执行

pool.close()
pool.join()

```

当然，也可以用with关键字，以上下文的方式操作pool:
```python
from multiprocessing import Manager, Pool

onlock_dict = Manager().dict() # 作为锁使用的字典
queue = Manager().Queue() # 通信用队列

def handle(q):
    data = q.get()
    dosomething(data) # 业务逻辑之类的
    did = onlock_dict.pop(data.id)# 释放锁

datas = get_data() #获取数据

with Pool(processes=4) as pool:
    for d in datas:
        if d.id in onlock_dict.keys():
            datas.append(d)
        else:
            onlock_dict[d.id] = 1
            queue.put(d)
            pool.apply(handle, (queue,)) 

```

在调用的结尾必须调用pool.close()和pool.join()以保证程序结束时子进程们也被结束，
close()的作用是组织后续任务提交到进程池，当所有任务执行完成后，工作进程会退出。
join()的作用是等待工作进程结束。调用 join() 前必须先调用 close() 或者 terminate() 。
terminate()的作用是不必等待未完成的任务，立即停止工作进程。当进程池对象被垃圾回收时， 
terminate()会立即调用。  
对于被放到queue里并执行了执行方法的对象，如果当前进程池占用满，那么会自动等待进程释放，释放之后自动执行。

python中还有另一种进程池`concurrent.futures.ProcessPoolExecutor`,我想，它与`multiprocessing.Pool`的
区别在于，`multiprocessing.Pool`会一直保持指定数量的子进程，而`concurrent.futures.ProcessPoolExecutor`
会释放进程，就像dbutils的数据库连接池PoolDB，随着调用创建进程直到达到最大数量，那么，它们在使用上是否有什么差别呢？
对比一下两种进程池的init:
`multiprocessing.Pool`:
```python
multiprocessing/pool.py
#
# Class representing a process pool
#
RUN = 0
CLOSE = 1
TERMINATE = 2
class Pool(object):
    '''
    Class which supports an async version of applying functions to arguments.
    '''
    _wrap_exception = True

    def Process(self, *args, **kwds):
        return self._ctx.Process(*args, **kwds)

    def __init__(self, processes=None, initializer=None, initargs=(),
                 maxtasksperchild=None, context=None):
        self._ctx = context or get_context()
        self._setup_queues()
        self._taskqueue = queue.SimpleQueue()
        self._cache = {}
        self._state = RUN
        self._maxtasksperchild = maxtasksperchild
        self._initializer = initializer
        self._initargs = initargs

        if processes is None:
            processes = os.cpu_count() or 1
        if processes < 1:
            raise ValueError("Number of processes must be at least 1")

        if initializer is not None and not callable(initializer):
            raise TypeError('initializer must be a callable')

        self._processes = processes
        self._pool = []
        self._repopulate_pool()

        self._worker_handler = threading.Thread(
            target=Pool._handle_workers,
            args=(self, )
            )
        self._worker_handler.daemon = True
        self._worker_handler._state = RUN
        self._worker_handler.start()


        self._task_handler = threading.Thread(
            target=Pool._handle_tasks,
            args=(self._taskqueue, self._quick_put, self._outqueue,
                  self._pool, self._cache)
            )
        self._task_handler.daemon = True
        self._task_handler._state = RUN
        self._task_handler.start()

        self._result_handler = threading.Thread(
            target=Pool._handle_results,
            args=(self._outqueue, self._quick_get, self._cache)
            )
        self._result_handler.daemon = True
        self._result_handler._state = RUN
        self._result_handler.start()

        self._terminate = util.Finalize(
            self, self._terminate_pool,
            args=(self._taskqueue, self._inqueue, self._outqueue, self._pool,
                  self._worker_handler, self._task_handler,
                  self._result_handler, self._cache),
            exitpriority=15
            )
```

`concurrent.futures.ProcessPoolExecutor`:
```python
"""Implements ProcessPoolExecutor.

The follow diagram and text describe the data-flow through the system:

|======================= In-process =====================|== Out-of-process ==|

+----------+     +----------+       +--------+     +-----------+    +---------+
|          |  => | Work Ids |       |        |     | Call Q    |    | Process |
|          |     +----------+       |        |     +-----------+    |  Pool   |
|          |     | ...      |       |        |     | ...       |    +---------+
|          |     | 6        |    => |        |  => | 5, call() | => |         |
|          |     | 7        |       |        |     | ...       |    |         |
| Process  |     | ...      |       | Local  |     +-----------+    | Process |
|  Pool    |     +----------+       | Worker |                      |  #1..n  |
| Executor |                        | Thread |                      |         |
|          |     +----------- +     |        |     +-----------+    |         |
|          | <=> | Work Items | <=> |        | <=  | Result Q  | <= |         |
|          |     +------------+     |        |     +-----------+    |         |
|          |     | 6: call()  |     |        |     | ...       |    |         |
|          |     |    future  |     |        |     | 4, result |    |         |
|          |     | ...        |     |        |     | 3, except |    |         |
+----------+     +------------+     +--------+     +-----------+    +---------+

Executor.submit() called:
- creates a uniquely numbered _WorkItem and adds it to the "Work Items" dict
- adds the id of the _WorkItem to the "Work Ids" queue

Local worker thread:
- reads work ids from the "Work Ids" queue and looks up the corresponding
  WorkItem from the "Work Items" dict: if the work item has been cancelled then
  it is simply removed from the dict, otherwise it is repackaged as a
  _CallItem and put in the "Call Q". New _CallItems are put in the "Call Q"
  until "Call Q" is full. NOTE: the size of the "Call Q" is kept small because
  calls placed in the "Call Q" can no longer be cancelled with Future.cancel().
- reads _ResultItems from "Result Q", updates the future stored in the
  "Work Items" dict and deletes the dict entry

Process #1..n:
- reads _CallItems from "Call Q", executes the calls, and puts the resulting
  _ResultItems in "Result Q"
"""
class ProcessPoolExecutor(_base.Executor):
    def __init__(self, max_workers=None, mp_context=None,
                 initializer=None, initargs=()):
        """Initializes a new ProcessPoolExecutor instance.

        Args:
            max_workers: The maximum number of processes that can be used to
                execute the given calls. If None or not given then as many
                worker processes will be created as the machine has processors.
            mp_context: A multiprocessing context to launch the workers. This
                object should provide SimpleQueue, Queue and Process.
            initializer: An callable used to initialize worker processes.
            initargs: A tuple of arguments to pass to the initializer.
        """
        _check_system_limits()

        if max_workers is None:
            self._max_workers = os.cpu_count() or 1
        else:
            if max_workers <= 0:
                raise ValueError("max_workers must be greater than 0")

            self._max_workers = max_workers

        if mp_context is None:
            mp_context = mp.get_context()
        self._mp_context = mp_context

        if initializer is not None and not callable(initializer):
            raise TypeError("initializer must be a callable")
        self._initializer = initializer
        self._initargs = initargs

        # Management thread
        self._queue_management_thread = None

        # Map of pids to processes
        self._processes = {}

        # Shutdown is a two-step process.
        self._shutdown_thread = False
        self._shutdown_lock = threading.Lock()
        self._broken = False
        self._queue_count = 0
        self._pending_work_items = {}

        # Create communication channels for the executor
        # Make the call queue slightly larger than the number of processes to
        # prevent the worker processes from idling. But don't make it too big
        # because futures in the call queue cannot be cancelled.
        queue_size = self._max_workers + EXTRA_QUEUED_CALLS
        self._call_queue = _SafeQueue(
            max_size=queue_size, ctx=self._mp_context,
            pending_work_items=self._pending_work_items)
        # Killed worker processes can produce spurious "broken pipe"
        # tracebacks in the queue's own worker thread. But we detect killed
        # processes anyway, so silence the tracebacks.
        self._call_queue._ignore_epipe = True
        self._result_queue = mp_context.SimpleQueue()
        self._work_ids = queue.Queue()

        # _ThreadWakeup is a communication channel used to interrupt the wait
        # of the main loop of queue_manager_thread from another thread (e.g.
        # when calling executor.submit or executor.shutdown). We do not use the
        # _result_queue to send the wakeup signal to the queue_manager_thread
        # as it could result in a deadlock if a worker process dies with the
        # _result_queue write lock still acquired.
        self._queue_management_thread_wakeup = _ThreadWakeup()

```
参数也差不多。。

那么，接下来我们进行一些实验:

show you my code:
```python
from multiprocessing import Manager, Pool,active_children
import concurrent.futures
import logging
import math
import time

logger=logging.Logger(name='123')
consolehandler = logging.StreamHandler()
filehandler = logging.FileHandler(filename="tornado-l")
logger.addHandler(consolehandler)
logger.addHandler(filehandler)

def handle(q):
    data = q
    data += 1
    time.sleep(10)
    return data


datas = [1, 2, 3, 4, 5, 6,7,8,9]  # 获取数据

if __name__ == "__main__":
    onlock_dict = Manager().dict()  # 作为锁使用的字典
    queue = Manager().Queue()  # 通信用队列
    with Pool(processes=3) as pool:  #  multiprocessing.Pool
        print(active_children())#查看激活的子进程
        print(pool.map(handle,datas))

    with concurrent.futures.ProcessPoolExecutor(3) as executor:  #  concurrent.futures.ProcessPoolExecutor
        print(active_children())
        for number, prime in zip(datas, executor.map(handle, datas)):
            print('%d is prime: %s' % (number, prime))
```

`multiprocessing.Pool`的结果：
```python
console:
[<SpawnProcess name='SpawnPoolWorker-4' pid=39372 parent=39367 started daemon>,
 <SpawnProcess name='SyncManager-1' pid=39369 parent=39367 started>, 
<SpawnProcess name='SyncManager-2' pid=39370 parent=39367 started>, 
<SpawnProcess name='SpawnPoolWorker-3' pid=39371 parent=39367 started daemon>, 
<SpawnProcess name='SpawnPoolWorker-5' pid=39373 parent=39367 started daemon>]

ps -ef |grep python:
 yuhan@yuhandeMacBook-Pro ⮀ ~ ⮀ ps -ef |grep python
  501 38075  7118   0  3:03下午 ttys002    0:00.00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn python
  501 38064 32885   0  3:03下午 ttys005    0:00.09 python test.py
  501 38065 38064   0  3:03下午 ttys005    0:00.04 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.resource_tracker import main;main(6)
  501 38066 38064   0  3:03下午 ttys005    0:00.07 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=9) --multiprocessing-fork
  501 38067 38064   0  3:03下午 ttys005    0:00.07 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=11) --multiprocessing-fork
  501 38068 38064   0  3:03下午 ttys005    0:00.06 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=23) --multiprocessing-fork
  501 38069 38064   0  3:03下午 ttys005    0:00.06 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=25) --multiprocessing-fork
  501 38070 38064   0  3:03下午 ttys005    0:00.06 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=27) --multiprocessing-fork
  501 38071 38064   0  3:03下午 ttys005    0:00.06 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=29) --multiprocessing-fork
```

`concurrent.futures.ProcessPoolExecutor`的结果：
```python
console:
[<SpawnProcess name='SyncManager-1' pid=39830 parent=39828 started>, <SpawnProcess name='SyncManager-2' pid=39831 parent=39828 started>]
[<SpawnProcess name='SyncManager-1' pid=39830 parent=39828 started>, <SpawnProcess name='SpawnProcess-3' pid=39832 parent=39828 started>, <SpawnProcess name='SyncManager-2' pid=39831 parent=39828 started>, <SpawnProcess name='SpawnProcess-5' pid=39834 parent=39828 started>, <SpawnProcess name='SpawnProcess-4' pid=39833 parent=39828 started>]
1 is prime: 2
[<SpawnProcess name='SyncManager-1' pid=39830 parent=39828 started>, <SpawnProcess name='SpawnProcess-3' pid=39832 parent=39828 started>, <SpawnProcess name='SyncManager-2' pid=39831 parent=39828 started>, <SpawnProcess name='SpawnProcess-5' pid=39834 parent=39828 started>, <SpawnProcess name='SpawnProcess-4' pid=39833 parent=39828 started>]
2 is prime: 3
[<SpawnProcess name='SyncManager-1' pid=39830 parent=39828 started>, <SpawnProcess name='SpawnProcess-3' pid=39832 parent=39828 started>, <SpawnProcess name='SyncManager-2' pid=39831 parent=39828 started>, <SpawnProcess name='SpawnProcess-5' pid=39834 parent=39828 started>, <SpawnProcess name='SpawnProcess-4' pid=39833 parent=39828 started>]
3 is prime: 4
[<SpawnProcess name='SyncManager-1' pid=39830 parent=39828 started>, <SpawnProcess name='SpawnProcess-3' pid=39832 parent=39828 started>, <SpawnProcess name='SyncManager-2' pid=39831 parent=39828 started>, <SpawnProcess name='SpawnProcess-5' pid=39834 parent=39828 started>, <SpawnProcess name='SpawnProcess-4' pid=39833 parent=39828 started>]
4 is prime: 5
[<SpawnProcess name='SyncManager-1' pid=39830 parent=39828 started>, <SpawnProcess name='SpawnProcess-3' pid=39832 parent=39828 started>, <SpawnProcess name='SyncManager-2' pid=39831 parent=39828 started>, <SpawnProcess name='SpawnProcess-5' pid=39834 parent=39828 started>, <SpawnProcess name='SpawnProcess-4' pid=39833 parent=39828 started>]
5 is prime: 6
[<SpawnProcess name='SyncManager-1' pid=39830 parent=39828 started>, <SpawnProcess name='SpawnProcess-3' pid=39832 parent=39828 started>, <SpawnProcess name='SyncManager-2' pid=39831 parent=39828 started>, <SpawnProcess name='SpawnProcess-5' pid=39834 parent=39828 started>, <SpawnProcess name='SpawnProcess-4' pid=39833 parent=39828 started>]
6 is prime: 7
[<SpawnProcess name='SyncManager-1' pid=39830 parent=39828 started>, <SpawnProcess name='SpawnProcess-3' pid=39832 parent=39828 started>, <SpawnProcess name='SyncManager-2' pid=39831 parent=39828 started>, <SpawnProcess name='SpawnProcess-5' pid=39834 parent=39828 started>, <SpawnProcess name='SpawnProcess-4' pid=39833 parent=39828 started>]
7 is prime: 8
[<SpawnProcess name='SyncManager-1' pid=39830 parent=39828 started>, <SpawnProcess name='SpawnProcess-3' pid=39832 parent=39828 started>, <SpawnProcess name='SyncManager-2' pid=39831 parent=39828 started>, <SpawnProcess name='SpawnProcess-5' pid=39834 parent=39828 started>, <SpawnProcess name='SpawnProcess-4' pid=39833 parent=39828 started>]
8 is prime: 9
[<SpawnProcess name='SyncManager-1' pid=39830 parent=39828 started>, <SpawnProcess name='SpawnProcess-3' pid=39832 parent=39828 started>, <SpawnProcess name='SyncManager-2' pid=39831 parent=39828 started>, <SpawnProcess name='SpawnProcess-5' pid=39834 parent=39828 started>, <SpawnProcess name='SpawnProcess-4' pid=39833 parent=39828 started>]
9 is prime: 10
[<SpawnProcess name='SyncManager-1' pid=40491 parent=40489 started>, <SpawnProcess name='SpawnProcess-3' pid=40494 parent=40489 started>, <SpawnProcess name='SyncManager-2' pid=40493 parent=40489 started>, <SpawnProcess name='SpawnProcess-5' pid=40496 parent=40489 started>, <SpawnProcess name='SpawnProcess-4' pid=40495 parent=40489 started>]


ps -ef |grep python:
  501 39740  7118   0  3:18下午 ttys002    0:00.00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn python
  501 39728 32885   0  3:18下午 ttys005    0:00.09 python test.py
  501 39729 39728   0  3:18下午 ttys005    0:00.04 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.resource_tracker import main;main(6)
  501 39730 39728   0  3:18下午 ttys005    0:00.07 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=9) --multiprocessing-fork
  501 39731 39728   0  3:18下午 ttys005    0:00.07 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=11) --multiprocessing-fork
  501 39732 39728   0  3:18下午 ttys005    0:00.06 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=22) --multiprocessing-fork
  501 39733 39728   0  3:18下午 ttys005    0:00.06 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=24) --multiprocessing-fork
  501 39734 39728   0  3:18下午 ttys005    0:00.06 /Users/yuhan/.pyenv/versions/3.8.1/envs/blog/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=7, pipe_handle=26) --multiprocessing-fork
```

可以看出，multiprocessing.Pool进程池在创建之后马上就创建了3个子进程，而`concurrent.futures.ProcessPoolExecutor`则是在map操作开始的时候才创建子进程，但是最后并没有把这些子进程释放掉，并没有达到dbutils里"释放不用的连接"的效果。
子进程都是由fork方法产生的，也都被active_children()捕获到了SpawnProcess，所以这两种方式所产生的子进程本身并没什么不同
并且它们都支持with方法进行上下文操作，所以在使用上，这两种连接池是一样的。